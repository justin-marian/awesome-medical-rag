<div align="center">

# :hospital: Awesome Medical & Multilingual <br> QA/RAG Research Papers

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re) [![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/) [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/justin-marian/awesome-medical-rag) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](http://makeapullrequest.com)

[![GitHub stars](https://img.shields.io/github/stars/justin-marian/awesome-medical-rag?style=flat&color=yellow&label=Stars)](https://github.com/justin-marian/awesome-medical-rag/stargazers) [![GitHub forks](https://img.shields.io/github/forks/justin-marian/awesome-medical-rag?style=flat&color=orange&label=Forks)](https://github.com/justin-marian/awesome-medical-rag/network) [![GitHub watchers](https://img.shields.io/github/watchers/justin-marian/awesome-medical-rag?style=flat&label=Watchers)](https://github.com/justin-marian/awesome-medical-rag/watchers) [![GitHub last commit](https://img.shields.io/github/last-commit/justin-marian/awesome-medical-rag?color=blue&label=Last%20Update)](https://github.com/justin-marian/awesome-medical-rag/commits/main) [![GitHub issues](https://img.shields.io/github/issues/justin-marian/awesome-medical-rag?color=red)](https://github.com/justin-marian/awesome-medical-rag/issues) [![GitHub pull requests](https://img.shields.io/github/issues-pr/justin-marian/awesome-medical-rag?color=purple)](https://github.com/justin-marian/awesome-medical-rag/pulls) [![GitHub contributors](https://img.shields.io/github/contributors/justin-marian/awesome-medical-rag?color=teal)](https://github.com/justin-marian/awesome-medical-rag/graphs/contributors)

</div>

<br>

> [!TIP]
> **The Definitive Knowledge Hub for Medical AI**
>
> Welcome to a meticulously curated collection of **200+** research papers, datasets, and benchmarks. This repository bridges the gap between **Structured Medical Knowledge** (Knowledge Graphs) and **Generative Reasoning** (LLMs), focusing on:
> * **Retrieval-Augmented Generation (RAG):** Techniques to ground AI in factual clinical data.
> * **Multilingual Equity:** Ensuring medical AI works across diverse languages and cultures.
> * **Complex Reasoning:** Moving from simple Q&A to multi-hop clinical decision support.

> [!NOTE]
> **How to Navigate**
>
> Oganized based on the research taxonomically to help you find exactly what you need:
> * **By Method:** Looking for *GraphRAG*, *PEFT*, or *Visual QA*?
> * **By Domain:** Interested in *Mental Health*, *Legal*, or *Finance*?
>
> Use the [**Table of Contents**](#-table-of-contents) below to jump straight to your area of interest.

---

## :scroll: Table of Contents

- [:hospital: Awesome Medical \& Multilingual  QA/RAG Research Papers](#hospital-awesome-medical--multilingual--qarag-research-papers)
  - [:scroll: Table of Contents](#scroll-table-of-contents)
  - [:dna: Medical \& Clinical LLMs](#dna-medical--clinical-llms)
  - [:books: Multilingual \& Cross-Lingual QA](#books-multilingual--cross-lingual-qa)
  - [:link: Knowledge Graphs \& Reasoning](#link-knowledge-graphs--reasoning)
  - [:magnet: RAG \& Retrieval Systems](#magnet-rag--retrieval-systems)
  - [:brain: Specialized Domains (Mental Health, Finance, Legal)](#brain-specialized-domains-mental-health-finance-legal)
  - [:trophy: Benchmarks \& Datasets](#trophy-benchmarks--datasets)
  - [:camera: Multimodal \& Visual QA](#camera-multimodal--visual-qa)
  - [:telescope: Future Horizons](#telescope-future-horizons)

---

## :dna: Medical & Clinical LLMs

> [!IMPORTANT]
> **Foundational Models & Clinical Adaptations**
>
> This section aggregates Large Language Models (LLMs) rigorously adapted for the medical domain. It encompasses a spectrum of methodologies from **Continued Pre-training** on biomedical corpora to **Instruction Fine-tuning** and **Parameter-Efficient Fine-Tuning (PEFT)**. These models bridge the gap between general-purpose AI and the high-stakes requirements of clinical reasoning and healthcare NLP.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **Medical Adaption** | <small>HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2311.09774-b31b1b.svg)](https://arxiv.org/abs/2311.09774) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/FreedomIntelligence/HuatuoGPT-II) [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=eJ3cHNu7ss) | One-stage training for medical adaption. |
| **QA System** | <small>SPBERTQA: A Two-Stage Question Answering System Based on Sentence Transformers for Medical Texts</small> | [![arXiv](https://img.shields.io/badge/arXiv-2206.09600-b31b1b.svg)](https://arxiv.org/abs/2206.09600) [![Springer](https://img.shields.io/badge/Springer-Link-blue)](https://link.springer.com/chapter/10.1007/978-3-031-10986-7_30) | 2-Stage QA based on Sentence Transformers. |
| **Medical LLM** | <small>Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain</small> | [![arXiv](https://img.shields.io/badge/arXiv-2404.07613-b31b1b.svg)](https://arxiv.org/abs/2404.07613) [![ACL](https://img.shields.io/badge/ACL-LREC%202024-red)](https://aclanthology.org/2024.lrec-main.974/) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/papers/2404.07613) | Multilingual T5 for medical domain. |
| **Closed-Domain QA** | <small>Large Language Models Encode Clinical Knowledge (Med-PaLM)</small> | [![Nature](https://img.shields.io/badge/Journal-Nature-blue)](https://www.nature.com/articles/s41586-023-06291-2) [![arXiv](https://img.shields.io/badge/arXiv-2212.13138-b31b1b.svg)](https://arxiv.org/abs/2212.13138) | Seminal Med-PaLM paper. |
| **Medical Tuning** | <small>ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data and Comprehensive Evaluation</small> | [![arXiv](https://img.shields.io/badge/arXiv-2306.09968-b31b1b.svg)](https://arxiv.org/abs/2306.09968) [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/371684579_ClinicalGPT_Large_Language_Models_Finetuned_with_Diverse_Medical_Data_and_Comprehensive_Evaluation) | Fine-tuning on diverse data. |
| **Clinical Fine-Tune** | <small>LlamaCare: An Instruction Fine-Tuned Large Language Model for Clinical NLP</small> | [![ACL](https://img.shields.io/badge/ACL-LREC%202024-red)](https://aclanthology.org/2024.lrec-main.930/) [![SemanticScholar](https://img.shields.io/badge/Semantic-Scholar-blue)](https://www.semanticscholar.org/paper/LlamaCare%3A-An-Instruction-Fine-Tuned-Large-Language-Li-Wang/b93fdc45061f9c415ad96c99e1d3198756c50d37) | Instruction fine-tuned LLaMA. |
| **Virtual Assistant** | <small>KG-Infused LLM for Virtual Health Assistant: Accelerated Inference and Enhanced Performance</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10903426) | KG-infused LLM assistant. |
| **Safe MedLLM** | <small>Medical Graph RAG: Towards Safe Medical Large Language Model via Graph RAG</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202025-red)](https://aclanthology.org/2025.acl-long.1381/) [![arXiv](https://img.shields.io/badge/arXiv-2408.04187-b31b1b.svg)](https://arxiv.org/abs/2408.04187) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/MedicineToken/Medical-Graph-RAG) | MedGraphRAG framework. |
| **Clinical PEFT** | <small>Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain</small> | [![ACL](https://img.shields.io/badge/ACL-ClinicalNLP-red)](https://aclanthology.org/2024.clinicalnlp-1.9/) [![arXiv](https://img.shields.io/badge/arXiv-2307.03042-b31b1b.svg)](https://arxiv.org/abs/2307.03042) | Clinical LLaMA-LoRA. |
| **French Model** | <small>DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical Domains</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202023-red)](https://aclanthology.org/2023.acl-long.896/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/DrBERT-Organization/DrBERT) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/Dr-BERT/DrBERT-7GB) | BERT for French Bio/Clinical. |
| **Spanish Biomed** | <small>Pretrained Biomedical Language Models for Clinical NLP in Spanish</small> | [![ACL](https://img.shields.io/badge/ACL-BioNLP-red)](https://aclanthology.org/2022.bionlp-1.19/) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/PlanTL-GOB-ES/bsc-bio-ehr-es) | Beteo / RoBERTa-es. |
| **Vietnamese Health** | <small>ViHealthBERT: Pre-trained Language Models for Vietnamese in Health Text Mining</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2022.lrec-1.35/) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/demdecuong/vihealthbert-base-word) | ViHealthBERT. |
| **TCM Tuning** | <small>HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge</small> | [![arXiv](https://img.shields.io/badge/arXiv-2304.06975-b31b1b.svg)](https://arxiv.org/abs/2304.06975) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | HuaTuo (LLaMA tuning). |
| **Complex Reasoning** | <small>HuatuoGPT-o1: Towards Medical Complex Reasoning with LLMs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2412.18925-b31b1b.svg)](https://arxiv.org/abs/2412.18925) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/FreedomIntelligence/HuatuoGPT-o1) | O1-like medical reasoning. |
| **Japanese 70B** | <small>70B-parameter Large Language Models in Japanese Medical Question-Answering</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/381652469_70B-parameter_large_language_models_in_Japanese_medical_question-answering) | 70B Japanese Medical LLM. |
| **Clinical Mamba** | <small>ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.05795-b31b1b.svg)](https://arxiv.org/abs/2403.05795) | Mamba model for clinical notes. |
| **Trilingual LLM** | <small>ELAINE-medLLM: Lightweight English Japanese Chinese Trilingual Large Language Model</small> | [![ACL](https://img.shields.io/badge/ACL-COLING%202025-red)](https://aclanthology.org/2025.coling-main.313/) | En-Jp-Zh Medical LLM. |
| **Note Gen** | <small>A Continued Pretrained LLM Approach for Automatic Medical Note Generation</small> | [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2024.naacl-short.47/) [![arXiv](https://img.shields.io/badge/arXiv-2403.09057-b31b1b.svg)](https://arxiv.org/abs/2403.09057) | Auto note generation. |
| **Clinical Needs** | <small>Do We Still Need Clinical LLMs?</small> | [![arXiv](https://img.shields.io/badge/arXiv-2402.04381-b31b1b.svg)](https://arxiv.org/abs/2402.04381) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/papers/2402.04381) | Questioning need for specialized LLMs. |
| **French Biomed** | <small>AliBERT: A Pre-trained Language Model for French Biomedical Text</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/372918929_AliBERT_A_Pre-trained_Language_Model_for_French_Biomedical_Text) | AliBERT. |
| **Portuguese** | <small>BioBERTpt: A Portuguese Neural Language Model for Clinical NER</small> | [![ACL](https://img.shields.io/badge/ACL-ClinicalNLP-red)](https://aclanthology.org/2020.clinicalnlp-1.7/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/HAILab-PUCPR/BioBERTpt) | BioBERTpt. |
| **Portuguese Card** | <small>CardioBERTpt: Transformer-based Models for Cardiology Language Representation</small> | [![ACL](https://img.shields.io/badge/ACL-ClinicalNLP-red)](https://aclanthology.org/2022.clinicalnlp-1.15/) | CardioBERTpt. |
| **Spanish Clinical** | <small>Clinical Flair: A Pre-Trained Language Model for Spanish Clinical NLP</small> | [![ACL](https://img.shields.io/badge/ACL-ClinicalNLP-red)](https://aclanthology.org/2022.clinicalnlp-1.9/) | Clinical Flair. |
| **Spanish Pre-train** | <small>Development of pre-trained language models for clinical NLP in Spanish</small> | [![ACL](https://img.shields.io/badge/ACL-EACL-red)](https://aclanthology.org/2023.eacl-srw.5/) | Pre-trained models for Spanish. |
| **Vietnamese Biomed** | <small>ViPubmedDeBERTa: A Pre-trained Model for Vietnamese Biomedical Text</small> | [![ACL](https://img.shields.io/badge/ACL-PACLIC-red)](https://aclanthology.org/2023.paclic-1.83/) | ViPubmedDeBERTa. |
| **Chinese LLM** | <small>Zhongjing: Enhancing Chinese Medical LLM through Expert Feedback</small> | [![AAAI](https://img.shields.io/badge/AAAI-29907-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/29907) [![arXiv](https://img.shields.io/badge/arXiv-2308.03549-b31b1b.svg)](https://arxiv.org/abs/2308.03549) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/SupritYoung/Zhongjing) | Zhongjing model. |
| **Textbook Aug** | <small>Augmenting Black-box LLMs with Medical Textbooks for Biomedical QA</small> | [![arXiv](https://img.shields.io/badge/arXiv-2309.02233-b31b1b.svg)](https://arxiv.org/abs/2309.02233) [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2024.findings-emnlp.95/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/TIGER-AI-Lab/LLM-AMT) | Textbook augmentation. |
| **Collaborative** | <small>MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning</small> | [![arXiv](https://img.shields.io/badge/arXiv-2311.10537-b31b1b.svg)](https://arxiv.org/abs/2311.10537) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/gersteinlab/MedAgents) | Multi-agent collaboration. |
| **BioBERT** | <small>MSQ-BioBERT: Ambiguity Resolution to Enhance BioBERT Medical QA</small> | [![ACM](https://img.shields.io/badge/ACM-Link-blue)](https://dl.acm.org/doi/abs/10.1145/3543507.3583878) [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=6BdJ5G5wEdp) | Ambiguity resolution. |
| **EHR Repr** | <small>MHGRL: An Effective Representation Learning Model for Electronic Health Records</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.985/) | Representation learning. |
| **CamemBERT** | <small>CamemBERT-bio: Leveraging Continual Pre-training on French Biomedical Data</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202023-red)](https://aclanthology.org/2023.acl-long.896/) [![arXiv](https://img.shields.io/badge/arXiv-2306.15550-b31b1b.svg)](https://arxiv.org/abs/2306.15550) | French domain adaptation. |
| **Japanese Eval** | <small>Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations</small> | [![arXiv](https://img.shields.io/badge/arXiv-2303.18027-b31b1b.svg)](https://arxiv.org/abs/2303.18027) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/jungokasai/IgakuQA) | IgakuQA Benchmark. |
| **Fine-tuning** | <small>Effects of Information Masking in the Task-Specific Finetuning of a Transformers-Based Clinical Question-Answering Framework</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/9874588) | Info masking in fine-tuning. |
| **Embeddings** | <small>MedITA_embeddings: Combining Contrastive Learning and Knowledge Graph Embeddings to develop medical word embeddings</small> | [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/rogerferrod/MedITA_embeddings) [![PMC](https://img.shields.io/badge/PMC-Article-blue)](https://pmc.ncbi.nlm.nih.gov/articles/PMC12719449/) | KG + Contrastive embeddings. |
| **Medical RL** | <small>Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination</small> | [![arXiv](https://img.shields.io/badge/arXiv-2508.12957-b31b1b.svg)](https://arxiv.org/abs/2508.12957) | Adaptive RL for medical reasoning. |
| **Reasoning RL** | <small>CAPO: Reinforcing Consistent Reasoning in Medical Decision-Making</small> | [![arXiv](https://img.shields.io/badge/arXiv-2506.12849-b31b1b.svg)](https://arxiv.org/abs/2506.12849) | Consistent reasoning via RL. |
| **Medical RL** | <small>Fleming-R1: Toward Expert-Level Medical Reasoning via Reinforcement Learning</small> | [![arXiv](https://img.shields.io/badge/arXiv-2509.15279-b31b1b.svg)](https://arxiv.org/abs/2509.15279) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/UbiquantAI/Fleming-R1) | Expert-level reasoning via RL. |
| **Unified Reasoning** | <small>Med-U1: Incentivizing Unified Medical Reasoning in LLMs via Large-scale Reinforcement Learning</small> | [![arXiv](https://img.shields.io/badge/arXiv-2506.12307-b31b1b.svg)](https://arxiv.org/abs/2506.12307) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/Monncyann/Med-U1) | Unified reasoning via RL. |
| **Reasoning Emergence** | <small>Med-RLVR: Emerging Medical Reasoning from a 3B Base Model via Reinforcement Learning</small> | [![arXiv](https://img.shields.io/badge/arXiv-2502.19655-b31b1b.svg)](https://arxiv.org/abs/2502.19655) | RL on 3B model. |
| **Diagnosis Reasoning** | <small>MedReason-R1: Learning to Reason for CT Diagnosis with Reinforcement Learning and Local Zoom</small> | [![arXiv](https://img.shields.io/badge/arXiv-2510.19626-b31b1b.svg)](https://arxiv.org/abs/2510.19626) | RL for CT diagnosis. |
| **Patient-Doctor** | <small>Dr. Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2025.emnlp-industry.125/) [![arXiv](https://img.shields.io/badge/arXiv-2507.11299-b31b1b.svg)](https://arxiv.org/abs/2507.11299) | Romanian multi-agent assistant. |
| **Medical Advice** | <small>PIE-Med: Predicting, Interpreting and Explaining Medical Recommendations</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/390512323_PIE-Med_Predicting_Interpreting_and_Explaining_Medical_Recommendations) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/picuslab/PIE-Med) | Predict-Interpret-Explain. |
| **Error Detection** | <small>Maven at MEDIQA-CORR 2024: Leveraging RAG and Medical LLM for Error Detection and Correction in Medical Notes</small> | [![ACL](https://img.shields.io/badge/ACL-ClinicalNLP-red)](https://aclanthology.org/2024.clinicalnlp-1.36/) | Error detection in notes. |
| **Structured Ext** | <small>Structured Extraction of Real World Medical Knowledge using LLMs for Summarization and Search</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10825160) [![arXiv](https://img.shields.io/badge/arXiv-2412.15256-b31b1b.svg)](https://arxiv.org/abs/2412.15256) | Structured extraction. |
| **Machine Reading** | <small>Towards Medical Machine Reading Comprehension with Structural Knowledge and Plain Text</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2020.emnlp-main.111/) | KMQA model. |
| **Virtual Patient** | <small>A Virtual Patient Dialogue System Based on Question-Answering on Clinical Records</small> | [![SemanticScholar](https://img.shields.io/badge/Semantic-Scholar-blue)](https://www.semanticscholar.org/paper/A-Virtual-Patient-Dialogue-System-Based-on-on-Arana-Idoyaga/b3e60ccbbcdace63eab1d0fb181a49ff41901df3) | Virtual Patient Dialogue. |
| **Herbal Medicine** | <small>ViHerbQA: A Robust QA Model for Vietnamese Traditional Herbal Medicine</small> | [![ACL](https://img.shields.io/badge/ACL-PACLIC-red)](https://aclanthology.org/2024.paclic-1.45/) | Vietnamese Herbal Medicine QA. |
| **Rule-Free** | <small>A Rule-Free Approach for Cardiological Registry Filling from Italian Clinical Notes with Question Answering Transformers</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/371299952_A_Rule-Free_Approach_for_Cardiological_Registry_Filling_from_Italian_Clinical_Notes_with_Question_Answering_Transformers) [![Springer](https://img.shields.io/badge/Springer-Link-blue)](https://link.springer.com/chapter/10.1007/978-3-031-34344-5_26) | Cardiological registry filling. |
| **Clinical Cases** | <small>Using Structured Health Information for Controlled Generation of Clinical Cases in French</small> | [![ACL](https://img.shields.io/badge/ACL-ClinicalNLP-red)](https://aclanthology.org/2024.clinicalnlp-1.14/) | Generating French clinical cases. |
| **Zero-Shot Clinical** | <small>Zero-Shot Clinical Questionnaire Filling From Human-Machine Interactions</small> | [![ACL](https://img.shields.io/badge/ACL-MRQA-red)](https://aclanthology.org/2021.mrqa-1.12/) | Zero-shot questionnaire filling. |
| **Safety Reports** | <small>Automatic Job Safety Report Generation using RAG-based LLMs</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10651320/) [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/383896910_Automatic_Job_Safety_Report_Generation_using_RAG-based_LLMs) | Job safety report generation. |
| **Biomed Reasoning** | <small>Hierarchical Representation-based Dynamic Reasoning Network for Biomedical Question Answering (HDRN)</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2022.coling-1.127/) | HDRN for Biomedical QA. |
| **QA Consistency** | <small>Are Large Language Models Consistent in Health-Related Question Answering?</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.00392-b31b1b.svg)](https://arxiv.org/abs/2403.00392) | Consistency check in Health QA. |
| **Entity Masking** | <small>Boosting Low-Resource Biomedical QA via Entity-Aware Masking Strategies</small> | [![ACL](https://img.shields.io/badge/ACL-EACL-red)](https://aclanthology.org/2021.eacl-main.169/) | Entity-aware masking strategies. |
| **Biomed QA** | <small>Biomedical Question Answering Systems into Practice: A Survey</small> | [![arXiv](https://img.shields.io/badge/arXiv-2005.05059-b31b1b.svg)](https://arxiv.org/abs/2005.05059) [![Journal](https://img.shields.io/badge/Journal-Elsevier-orange)](https://www.sciencedirect.com/science/article/pii/S0306457320300936) | Survey of BioMed QA systems. |
| **Search / Dialogue** | <small>Anticipating Follow-Up Questions in Exploratory Information Search</small> | [![ACL](https://img.shields.io/badge/ACL-SIGDIAL-red)](https://aclanthology.org/2024.sigdial-1.9/) | Follow-up question prediction. |
| **Exam Generation** | <small>From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams</small> | [![arXiv](https://img.shields.io/badge/arXiv-2206.05442-b31b1b.svg)](https://arxiv.org/abs/2206.05442) [![ACM](https://img.shields.io/badge/ACM-Link-blue)](https://dl.acm.org/doi/10.1145/3580305.3599827) | ML Exam generation/answering. |
| **French NER** | <small>A Benchmark Evaluation of Clinical Named Entity Recognition in French</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.19726-b31b1b.svg)](https://arxiv.org/abs/2403.19726) [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.2/) | Clinical NER in French. |
| **Chinese Medical** | <small>Benchmarking Large Language Models on CMExam: A Comprehensive Chinese Medical Examination Dataset</small> | [![arXiv](https://img.shields.io/badge/arXiv-2306.02096-b31b1b.svg)](https://arxiv.org/abs/2306.02096) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/CMExam/CMExam) | CMExam benchmark. |
| **DrQA** | <small>Reading Wikipedia to Answer Open-Domain Questions (DrQA)</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202017-red)](https://aclanthology.org/P17-1171/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/facebookresearch/DrQA) | Seminal DrQA paper. |
| **Few-shot QA** | <small>Gotta: Generative Few-shot Question Answering by Prompt-based Cloze Data Augmentation</small> | [![SIAM](https://img.shields.io/badge/SIAM-SDM-blue)](https://epubs.siam.org/doi/abs/10.1137/1.9781611977653.ch10) | Prompt-based data augmentation. |
| **Spoken QA** | <small>A Framework for Automatic Generation of Spoken Question-Answering Data</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2022.findings-emnlp.342/) | Spoken QA data generation. |
| **Non-factoid QA** | <small>MICRON: Multigranular Interaction for Contextualizing RepresentatiON in Non-factoid Question Answering</small> | [![ACL](https://img.shields.io/badge/ACL-D19-red)](https://aclanthology.org/D19-1601/) | MICRON model. |
| **Synthetic QA** | <small>Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Model</small> | [![ACL](https://img.shields.io/badge/ACL-PACLIC-red)](https://aclanthology.org/2023.paclic-1.78/) | Synthetic training data. |
| **Hebrew NLP** | <small>Transformer-based Hebrew NLP models for Short Answer Scoring in Biology</small> | [![ACL](https://img.shields.io/badge/ACL-BEA-red)](https://aclanthology.org/2023.bea-1.46/) | Hebrew Short Answer Scoring. |
| **Data Selection** | <small>Data Selection for Language Models: A Survey</small> | [![arXiv](https://img.shields.io/badge/arXiv-2402.16727-b31b1b.svg)](https://arxiv.org/abs/2402.16727) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/alon-albalak/data-selection-survey) | Survey on data selection. |
| **QA Eval** | <small>Evaluating Open-QA Evaluation</small> | [![NeurIPS](https://img.shields.io/badge/NeurIPS-2023-blue)](https://proceedings.neurips.cc/paper_files/paper/2023/hash/f323d594aa5d2c68154433a131c07959-Abstract-Datasets_and_Benchmarks.html) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/wangcunxiang/QA-Eval) | Evaluation of QA evaluation. |
| **Explainable QA** | <small>Explainable Bilingual Medical-Question-Answering Model Using Ensemble Learning Technique</small> | [![MDPI](https://img.shields.io/badge/MDPI-Electronics-blue)](https://www.mdpi.com/2079-9292/14/20/4128) | Bilingual Explainable QA. |
| **Hint Gen** | <small>HintQA: Exploring Hint Generation Approaches in Open-Domain Question Answering</small> | [![arXiv](https://img.shields.io/badge/arXiv-2409.16096-b31b1b.svg)](https://arxiv.org/abs/2409.16096) [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2024.findings-emnlp.546/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/DataScienceUIBK/HintQA) | Hint generation for ODQA. |
| **Memory QA** | <small>Omne-R1: Learning to Reason with Memory for Multi-hop Question Answering</small> | [![arXiv](https://img.shields.io/badge/arXiv-2508.17330-b31b1b.svg)](https://arxiv.org/abs/2508.17330) | Reasoning with Memory. |

---

## :books: Multilingual & Cross-Lingual QA

> [!IMPORTANT]
> **Breaking Language Barriers**
>
> This section is dedicated to democratizing AI access through **Cross-Lingual Transfer** and **Multilingual RAG**. It features benchmarks for under-represented languages (e.g., Amharic, Tigrinya, Kazakh), techniques for cultural alignment, and strategies to bridge the performance gap between high-resource and low-resource linguistic domains.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **Multilingual Adapters** | <small>Adapters for Enhanced Modeling of Multilingual Knowledge and Text</small> | [![arXiv](https://img.shields.io/badge/arXiv-2210.13617-b31b1b.svg)](https://arxiv.org/abs/2210.13617) [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2022.findings-emnlp.287/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/yifan-h/Multilingual_Space) | Enhanced modeling adapters. |
| **Entity Alignment** | <small>Aligning Cross-Lingual Entities with Multi-Aspect Information</small> | [![arXiv](https://img.shields.io/badge/arXiv-1910.06575-b31b1b.svg)](https://arxiv.org/abs/1910.06575) [![ACL](https://img.shields.io/badge/ACL-D19-red)](https://aclanthology.org/D19-1451/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/THU-KEG/Entity_Alignment_Papers) | Multi-aspect alignment. |
| **Arabic Medical** | <small>AraMed: Arabic Medical Question Answering using Pretrained Transformer Language Models</small> | [![ACL](https://img.shields.io/badge/ACL-OSACT-red)](https://aclanthology.org/2024.osact-1.6/) | Arabic Medical QA. |
| **Multi-Domain QA** | <small>M2QA: Multi-domain Multilingual Question Answering</small> | [![arXiv](https://img.shields.io/badge/arXiv-2407.01091-b31b1b.svg)](https://arxiv.org/abs/2407.01091) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/UKPLab/m2qa) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/datasets/UKPLab/m2qa) | M2QA benchmark. |
| **Cross-Lingual** | <small>XLM-K: Improving Cross-Lingual Language Model Pre-training with Multilingual Knowledge</small> | [![AAAI](https://img.shields.io/badge/AAAI-21330-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/21330) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/microsoft/Unicoder/tree/master/pretraining/xlmk) | Pre-training with multilingual knowledge. |
| **Prompt Transfer** | <small>Cross-Lingual Transfer for Natural Language Inference via Multilingual Prompt Translator</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.12407-b31b1b.svg)](https://arxiv.org/abs/2403.12407) | Multilingual prompt translation. |
| **Thai LLM** | <small>Representing the Under-Represented: Cultural and Core Capability Benchmarks for Thai LLMs</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.278/) | Thai cultural/core benchmarks. |
| **ICL Alignment** | <small>Improving In-context Learning of Multilingual Generative Language Models with Cross-lingual Alignment</small> | [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2024.naacl-long.445/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/chongli17/CrossLingualAlignment) | Cross-lingual alignment for ICL. |
| **Kazakh QA** | <small>KazQAD: Kazakh Open-Domain Question Answering Dataset</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.843/) [![arXiv](https://img.shields.io/badge/arXiv-2404.04487-b31b1b.svg)](https://arxiv.org/abs/2404.04487) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/IS2AI/KazQAD) | Kazakh open-domain QA. |
| **Multilingual RAG** | <small>Not All Languages are Equal: Insights into Multilingual Retrieval-Augmented Generation</small> | [![arXiv](https://img.shields.io/badge/arXiv-2410.21970-b31b1b.svg)](https://arxiv.org/abs/2410.21970) | Linguistic inequalities in RAG. |
| **Machine Translation** | <small>Enhancing Machine Translation Experiences with Multilingual Knowledge Graphs</small> | [![AAAI](https://img.shields.io/badge/AAAI-30563-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/30563) | MT with Multilingual KG. |
| **Amharic QA** | <small>Low Resource Question Answering: An Amharic Benchmarking Dataset (Amh-QuAD)</small> | [![ACL](https://img.shields.io/badge/ACL-RAIL-red)](https://aclanthology.org/2024.rail-1.14/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/semantic-systems/amharic-qa) | Amh-QuAD / AmQA. |
| **Tigrinya QA** | <small>Question-Answering in a Low-resourced Language: Benchmark Dataset and Models for Tigrinya</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202023-red)](https://aclanthology.org/2023.acl-long.661/) [![arXiv](https://img.shields.io/badge/arXiv-2305.18737-b31b1b.svg)](https://arxiv.org/abs/2305.18737) | Tigrinya QA benchmark. |
| **Portuguese QA** | <small>Pirá: A Bilingual Portuguese-English Dataset for Question-Answering</small> | [![ACM](https://img.shields.io/badge/ACM-Link-blue)](https://dl.acm.org/doi/10.1145/3459637.3482012) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/C4AI/Pira) | Pirá dataset. |
| **Zero-shot CoT** | <small>AutoCAP: Towards Automatic Cross-lingual Alignment Planning for Zero-shot Chain-of-Thought</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%20Findings-red)](https://aclanthology.org/2024.findings-acl.546/) | AutoCAP. |
| **Cultural QA** | <small>NativQA: Multilingual Culturally-Aligned Natural Query for LLMs</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%20Findings-red)](https://aclanthology.org/2025.findings-acl.770/) [![Code](https://img.shields.io/badge/Code-GitLab-orange)](https://gitlab.com/nativqa/multinativqa) | Culturally-aligned questions. |
| **Swedish NLP** | <small>A Benchmark for Swedish Clinical Natural Language Processing</small> | [![arXiv](https://img.shields.io/badge/arXiv-2308.08727-b31b1b.svg)](https://arxiv.org/abs/2308.08727) [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.120/) | Swedish Clinical NLP benchmark. |
| **Transferability** | <small>On the Cross-lingual Transferability of Monolingual Representations</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202020-red)](https://aclanthology.org/2020.acl-main.421/) [![arXiv](https://img.shields.io/badge/arXiv-1910.11856-b31b1b.svg)](https://arxiv.org/abs/1910.11856) | Monolingual transferability. |
| **Linguistic Inc** | <small>URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological and Multilingual Knowledge Base</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.463/) [![arXiv](https://img.shields.io/badge/arXiv-2409.18472-b31b1b.svg)](https://arxiv.org/abs/2409.18472) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/Masonshipton25/URIELPlus) | URIEL+ Knowledge Base. |
| **Prompt Transfer** | <small>Is Prompt Transfer Always Effective? An Empirical Study of Prompt Transfer for Question Answering</small> | [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2024.naacl-short.56/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/ailab-prompt-transfer/qa_prompt_transfer) | Empirical study on prompt transfer. |
| **Romanian Eval** | <small>Evaluation of Language Models on Romanian XQuAD and RoITD datasets</small> | [![Journal](https://img.shields.io/badge/Journal-IJCCC-blue)](https://univagora.ro/jour/index.php/ijccc/article/view/5111) | Romanian XQuAD/RoITD. |

---

## :link: Knowledge Graphs & Reasoning

> [!WARNING]
> **Bridging Structured & Unstructured Knowledge**
>
> This section dives into the complex integration of **Knowledge Graphs (KGs)** with Large Language Models. It covers advanced reasoning tasks such as **Multi-hop Reasoning**, **Subgraph Extraction**, and **Neuro-Symbolic** approaches. Papers here explore how to ground LLM generation in factual graph structures to improve accuracy and interpretability.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **KG Alignment** | <small>MRAEA: An Efficient and Robust Entity Alignment Approach for Cross-lingual KG</small> | [![ACM](https://img.shields.io/badge/ACM-Link-blue)](https://dl.acm.org/doi/10.1145/3336191.3371804) [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/338757649_MRAEA_An_Efficient_and_Robust_Entity_Alignment_Approach_for_Cross-lingual_Knowledge_Graph) | Cross-lingual KG alignment. |
| **Reasoning Eval** | <small>DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain QA over KB and Text</small> | [![arXiv](https://img.shields.io/badge/arXiv-2310.20170-b31b1b.svg)](https://arxiv.org/abs/2310.20170) | Reasoning over KB and Text. |
| **KG + LLM** | <small>ChatDoctor: A Medical Chat Model Fine-Tuned on LLaMA Using Medical Domain Knowledge</small> | [![arXiv](https://img.shields.io/badge/arXiv-2303.14070-b31b1b.svg)](https://arxiv.org/abs/2303.14070) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/Kent0n-Li/ChatDoctor) | LLaMA + Medical KG. |
| **KG Prompting** | <small>KG-CoT: Chain-of-Thought Prompting of LLMs over Knowledge Graphs</small> | [![IJCAI](https://img.shields.io/badge/IJCAI-2024-blue)](https://www.ijcai.org/proceedings/2024/734) | CoT over Knowledge Graphs. |
| **KG Sync** | <small>Domain Knowledge Exploration by Synchronizing Knowledge Graph and LLMs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2311.16124-b31b1b.svg)](https://arxiv.org/abs/2311.16124) | Synchronizing KG and LLMs. |
| **Dynamic Reasoning** | <small>Dynamic Hierarchical Reasoning with Language Model and Knowledge Graph (DRLK)</small> | [![arXiv](https://img.shields.io/badge/arXiv-2311.09139-b31b1b.svg)](https://arxiv.org/abs/2311.09139) [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/375739818_Dynamic_Hierarchical_Reasoning_with_Language_Model_and_Knowledge_Graph_for_Question_Answering) | Hierarchical reasoning with KG. |
| **Subgraph Reasoning** | <small>ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained Language Models</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2023.emnlp-main.228/) [![arXiv](https://img.shields.io/badge/arXiv-2401.00158-b31b1b.svg)](https://arxiv.org/abs/2401.00158) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/RUCAIBox/ReasoningLM) | Structural subgraph reasoning. |
| **Graph Reasoning** | <small>RoG: Reasoning on Graphs (Faithful and Interpretable LLM Reasoning)</small> | [![ICLR](https://img.shields.io/badge/ICLR-OpenReview-blue)](https://openreview.net/forum?id=C9y00Z56W7) [![arXiv](https://img.shields.io/badge/arXiv-2310.01061-b31b1b.svg)](https://arxiv.org/abs/2310.01061) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/RUC-KB-Reasoning/RoG) | Reasoning paths for QA. |
| **Graph Reasoning** | <small>KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using LLMs</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2023.findings-emnlp.631/) [![arXiv](https://img.shields.io/badge/arXiv-2310.11220-b31b1b.svg)](https://arxiv.org/abs/2310.11220) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/jiho283/KG-GPT) | KG-GPT framework. |
| **KG Integration** | <small>Bridging the Gap: Integrating Knowledge Graphs into LLMs for Complex QA</small> | [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=fQjPKAiNbF) | KG + LLM for complex QA. |
| **Multilingual KG** | <small>Joint Completion and Alignment of Multilingual Knowledge Graphs</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2022.emnlp-main.817/) [![arXiv](https://img.shields.io/badge/arXiv-2210.09033-b31b1b.svg)](https://arxiv.org/abs/2210.09033) | JMAC model. |
| **Knowledge Injection** | <small>KIMERA: Injecting Domain Knowledge into Vacant Transformer Heads</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2022.lrec-1.38/) | Retraining vacant heads. |
| **Quotes KG** | <small>QuoteKG: A Multilingual Knowledge Graph of Quotes</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/360958399_QuoteKG_A_Multilingual_Knowledge_Graph_of_Quotes) [![Project](https://img.shields.io/badge/Project-Website-blue)](https://quotekg.l3s.uni-hannover.de/) | KG of quotes (55 langs). |
| **TCM KG** | <small>Traditional Chinese Medicine Knowledge Graph Construction Based on LLMs</small> | [![MDPI](https://img.shields.io/badge/MDPI-Electronics-blue)](https://www.mdpi.com/2079-9292/13/7/1395) | TCM KG construction. |
| **Updating KG** | <small>Up To Date: Automatic Updating Knowledge Graphs Using LLMs</small> | [![Elsevier](https://img.shields.io/badge/Elsevier-Direct-orange)](https://www.sciencedirect.com/science/article/pii/S1877050924030072) | Auto updating KGs. |
| **Semi-supervised** | <small>Semi-supervised Entity Alignment via Joint Knowledge Embedding (KECG)</small> | [![ACL](https://img.shields.io/badge/ACL-D19-red)](https://aclanthology.org/D19-1274/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/THU-KEG/KECG) | KECG model. |
| **Alignment Transf.** | <small>Multi-Modal Knowledge Graph Transformer Framework for Entity Alignment</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2023.findings-emnlp.70/) | Meaformer. |
| **Contrastive** | <small>Multi-modal Contrastive Representation Learning for Entity Alignment</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2022.coling-1.227/) | MCLEA model. |
| **KBQA Framework** | <small>ChatKBQA: A Generate-then-Retrieve Framework for KBQA with Fine-tuned LLMs</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%20Findings-red)](https://aclanthology.org/2024.findings-acl.122/) [![arXiv](https://img.shields.io/badge/arXiv-2310.08975-b31b1b.svg)](https://arxiv.org/abs/2310.08975) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/ChatKBQA/ChatKBQA) | Generate-then-Retrieve. |
| **Few-Shot KBQA** | <small>KB-BINDER: A Unified Semantically Parsing Framework for KBQA</small> | [![arXiv](https://img.shields.io/badge/arXiv-2304.09540-b31b1b.svg)](https://arxiv.org/abs/2304.09540) | Few-shot semantic parsing. |
| **Semantic Parsing** | <small>LLM-based Semantic Parsing for Conversational QA over Knowledge Graphs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2310.10648-b31b1b.svg)](https://arxiv.org/abs/2310.10648) | Semantic parsing for ConvQA. |
| **Complex QA** | <small>KQA Pro: A Dataset with Explicit Compositional Programs for Complex KBQA</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202022-red)](https://aclanthology.org/2022.acl-long.422/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/shijx12/KQAPro_Baselines) | KQA Pro dataset. |
| **Rule-Guided** | <small>Rule-KBQA: Rule-Guided Reasoning for Complex KBQA with LLMs</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.562/) | Rule-guided reasoning. |
| **Medical KG** | <small>Research on Medical Question Answering System Based on Knowledge Graph</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/348854825_Research_on_Medical_Question_Answering_System_Based_on_Knowledge_Graph) | Neo4j-based Medical KG. |
| **Knowledge Injection** | <small>Infusing Disease Knowledge into BERT for Health QA and Inference</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2020.emnlp-main.372/) [![arXiv](https://img.shields.io/badge/arXiv-2010.03746-b31b1b.svg)](https://arxiv.org/abs/2010.03746) | Infusing knowledge into BERT. |
| **Journal KG** | <small>Construction of Journal Knowledge Graph Based on Deep Learning and LLM</small> | [![MDPI](https://img.shields.io/badge/MDPI-Electronics-blue)](https://www.mdpi.com/2079-9292/14/9/1728) [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/391130719_Construction_of_Journal_Knowledge_Graph_Based_on_Deep_Learning_and_LLM) | Journal KG construction. |
| **Alzheimer's QA** | <small>Dynamic Co-Augmentation of Large Language Models and Knowledge Graphs for Question Answering in Alzheimer's Disease Scientific Literature</small> | [![arXiv](https://img.shields.io/badge/arXiv-2410.15585-b31b1b.svg)](https://arxiv.org/abs/2410.15585) | Co-augmentation for Alzheimer's. |
| **Aviation QA** | <small>Knowledge Graph – Deep Learning: A Case Study in Question Answering in Aviation Safety Domain</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2022.lrec-1.673/) | Aviation safety KG-QA. |
| **Brain Disorders** | <small>Knowledge Graph and Its Application in the Study of Neurological and Mental Disorders</small> | [![Frontiers](https://img.shields.io/badge/Frontiers-Psychiatry-blue)](https://www.frontiersin.org/articles/10.3389/fpsyt.2025.1452557/full) [![PubMed](https://img.shields.io/badge/PubMed-40171303-green)](https://pubmed.ncbi.nlm.nih.gov/40171303/) | KG for brain disorders. |
| **Chronic Diseases** | <small>Research on Question Answering over Knowledge Graph of Chronic Diseases</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/370238088_Research_on_Question_Answering_over_Knowledge_Graph_of_Chronic_Diseases) | Chronic disease KG. |
| **Entity Alignment** | <small>Exploring the Impacts of Feature Fusion Strategy in Multi-modal Entity Alignment</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.522/) | Feature fusion in alignment. |
| **Object Prediction** | <small>Evaluating Prompt-based Question Answering for Object Prediction in the Open Research Knowledge Graph</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/370949842_Evaluating_Prompt-based_Question_Answering_for_Object_Prediction_in_the_Open_Research_Knowledge_Graph) | Prompt-based object prediction. |

---

## :magnet: RAG & Retrieval Systems

> [!TIP]
> **Augmenting Generation with External Knowledge**
>
> This section focuses on the critical integration of Retrieval-Augmented Generation (RAG) to mitigate hallucinations and ensure factual consistency. It covers the full lifecycle of RAG development: from **Dynamic Retrieval** and **Re-ranking** strategies to advanced **GraphRAG** implementations. Special emphasis is placed on **Evaluation Frameworks** designed to rigorously measure relevance, faithfulness, and answer credibility.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **RAG Evaluation** | <small>Adapting Standard Retrieval Benchmarks to Evaluate Generated Answers</small> | [![arXiv](https://img.shields.io/badge/arXiv-2401.04842-b31b1b.svg)](https://arxiv.org/abs/2401.04842) [![Springer](https://img.shields.io/badge/Springer-Link-blue)](https://link.springer.com/chapter/10.1007/978-3-031-56060-6_26) | Adapting benchmarks for RAG eval. |
| **RAG Relevance** | <small>DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented Generation</small> | [![arXiv](https://img.shields.io/badge/arXiv-2406.07348-b31b1b.svg)](https://arxiv.org/abs/2406.07348) | Dynamic document relevance. |
| **RAG Chatbots** | <small>Automated Question-Answer Generation for Evaluating RAG-based Chatbots</small> | [![ACL](https://img.shields.io/badge/ACL-CL4Health-red)](https://aclanthology.org/2024.cl4health-1.25/) | Auto QA generation for evaluation. |
| **RAG Queries** | <small>RichRAG: Crafting Rich Responses for Multi-faceted Queries in RAG</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.750/) [![arXiv](https://img.shields.io/badge/arXiv-2406.12566-b31b1b.svg)](https://arxiv.org/abs/2406.12566) | Handling multi-faceted queries. |
| **RAG Eval** | <small>Know Your RAG: Dataset Taxonomy and Generation Strategies for Evaluating RAG Systems</small> | [![arXiv](https://img.shields.io/badge/arXiv-2411.19710-b31b1b.svg)](https://arxiv.org/abs/2411.19710) | Taxonomy for RAG eval. |
| **Clinical RAG** | <small>ClinicalRAG: Enhancing Clinical Decision Support through Heterogeneous Knowledge Retrieval</small> | [![ACL](https://img.shields.io/badge/ACL-KnowLLM-red)](https://aclanthology.org/2024.knowllm-1.6/) | Heterogeneous retrieval for CDS. |
| **RAG Practices** | <small>Enhancing Retrieval-Augmented Generation: A Study of Best Practices</small> | [![arXiv](https://img.shields.io/badge/arXiv-2501.07391-b31b1b.svg)](https://arxiv.org/abs/2501.07391) | Study of RAG best practices. |
| **RAG Credibility** | <small>How Credible Is an Answer From Retrieval-Augmented LLMs?</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.285/) | Credibility in Multi-Hop QA. |
| **Adaptive RAG** | <small>Adaptive-RAG: Learning to Adapt RAG LLMs through Question Complexity</small> | [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2024.naacl-long.389/) [![arXiv](https://img.shields.io/badge/arXiv-2403.14403-b31b1b.svg)](https://arxiv.org/abs/2403.14403) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/starsuzi/Adaptive-RAG) | Adapting based on complexity. |
| **Knowledge Boundary** | <small>Investigating the Factual Knowledge Boundary of LLMs with Retrieval Augmentation</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.250/) [![arXiv](https://img.shields.io/badge/arXiv-2307.11019-b31b1b.svg)](https://arxiv.org/abs/2307.11019) | Factual boundaries in RAG. |
| **Ranking/Re-ranking** | <small>KG-Rank: Enhancing LLMs for Medical QA with Knowledge Graphs and Ranking Techniques</small> | [![ACL](https://img.shields.io/badge/ACL-BioNLP-red)](https://aclanthology.org/2024.bionlp-1.13/) [![arXiv](https://img.shields.io/badge/arXiv-2403.05881-b31b1b.svg)](https://arxiv.org/abs/2403.05881) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/YangRui525/KG-Rank) | Ranking with KGs. |
| **RAG Certainty** | <small>RAG Certainty: Quantifying the Certainty of Context-Based Responses by LLMs</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10903445) | RAG Certainty metric. |
| **Quantization** | <small>4-bit Quantization in Vector-Embedding for RAG</small> | [![arXiv](https://img.shields.io/badge/arXiv-2501.10534-b31b1b.svg)](https://arxiv.org/abs/2501.10534) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/taeheej/4bit-Quantization-in-Vector-Embedding-for-RAG) | 4-bit embedding quantization. |
| **KG-RAG** | <small>Knowledge Graph-extended Retrieval Augmented Generation (KG-RAG)</small> | [![arXiv](https://img.shields.io/badge/arXiv-2504.08893-b31b1b.svg)](https://arxiv.org/abs/2504.08893) [![Project](https://img.shields.io/badge/Project-Website-blue)](https://dsanmart.github.io/KG-RAG/) | KG extended RAG. |
| **Unified RAG** | <small>Reasoning by Exploration: A Unified Approach to Retrieval and Generation over Graphs (RoE)</small> | [![arXiv](https://img.shields.io/badge/arXiv-2510.07484-b31b1b.svg)](https://arxiv.org/abs/2510.07484) | Reasoning by Exploration. |
| **Region-First** | <small>ReGraM: Region-First Knowledge Graph Reasoning for Medical QA</small> | [![arXiv](https://img.shields.io/badge/arXiv-2601.09280-b31b1b.svg)](https://arxiv.org/abs/2601.09280) | Region-first reasoning. |
| **Dynamic Rank** | <small>DynRank: Improve Passage Retrieval with Dynamic Zero-Shot Prompting</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.319/) [![arXiv](https://img.shields.io/badge/arXiv-2412.00600-b31b1b.svg)](https://arxiv.org/abs/2412.00600) | DynRank. |
| **Re-Ranking** | <small>ASRank: Zero-Shot Re-Ranking with Answer Scent for Document Retrieval</small> | [![arXiv](https://img.shields.io/badge/arXiv-2501.15245-b31b1b.svg)](https://arxiv.org/abs/2501.15245) | ASRank. |
| **Low-Resource Retrieval** | <small>Unsupervised Domain Adaptation of Dense Retrieval via Zero-Shot Sim Transfer</small> | [![arXiv](https://img.shields.io/badge/arXiv-2112.07577-b31b1b.svg)](https://arxiv.org/abs/2112.07577) | Unsupervised domain adaptation. |
| **Passage Expansion** | <small>Knowledge Graph-Guided Retrieval Augmented Generation (KG$^2$RAG)</small> | [![arXiv](https://img.shields.io/badge/arXiv-2502.06864-b31b1b.svg)](https://arxiv.org/abs/2502.06864) | KG for chunk expansion. |
| **Copilot Reasoning** | <small>MedRAG: Enhancing RAG with KG-Elicited Reasoning for Healthcare Copilot</small> | [![arXiv](https://img.shields.io/badge/arXiv-2502.04413-b31b1b.svg)](https://arxiv.org/abs/2502.04413) [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=7C6cd95qvH) | MedRAG copilot. |
| **ConvRAG** | <small>Boosting Conversational Question Answering with Fine-Grained Retrieval-Augmentation</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.18243-b31b1b.svg)](https://arxiv.org/abs/2403.18243) | Fine-grained retrieval + self-check. |
| **Nutrigenetics** | <small>A Retrieval-Augmented Generation Application For Question-Answering in Nutrigenetics</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/383998708_Enhancing_Dietary_Supplement_Question_Answer_via_Retrieval-Augmented_Generation_RAG_with_LLM) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/johndef64/nutrig-graphrag) | Nutrigenetic GraphRAG. |
| **Reddit RAG** | <small>Two-Layer RAG Framework for Low-Resource Medical QA Using Reddit Data</small> | [![Journal](https://img.shields.io/badge/Journal-JMIR-blue)](https://www.jmir.org/2025/1/e66220) | Reddit-based Medical RAG. |
| **Query Reformulation** | <small>Semantic Grounding of LLMs Using Knowledge Graphs for Query Reformulation</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10825835) | Semantic grounding. |
| **TCM GraphRAG** | <small>OpenTCM: A GraphRAG-Empowered LLM-based System for TCM</small> | [![arXiv](https://img.shields.io/badge/arXiv-2504.20118-b31b1b.svg)](https://arxiv.org/abs/2504.20118) | GraphRAG for TCM. |
| **Knowledge Selection** | <small>FlexiQA: Leveraging LLM's Evaluation Capabilities for Flexible Knowledge Selection</small> | [![ACL](https://img.shields.io/badge/ACL-EACL-red)](https://aclanthology.org/2024.findings-eacl.4/) | Flexible knowledge selection. |
| **Historical RAG** | <small>HiRAG: A Historical Information-Driven RAG Framework for Summarization</small> | [![PMLR](https://img.shields.io/badge/PMLR-Link-blue)](https://proceedings.mlr.press/v260/zhou25a.html) | Historical info for summarization. |
| **Uncertainty** | <small>Modeling Uncertainty and Using Post-fusion as Fallback Improves RAG</small> | [![ACL](https://img.shields.io/badge/ACL-KnowLLM-red)](https://aclanthology.org/2024.knowllm-1.7/) | Post-fusion fallback. |
| **Context Use** | <small>Desiderata for the Context Use of Question Answering Systems</small> | [![ACL](https://img.shields.io/badge/ACL-EACL-red)](https://aclanthology.org/2024.eacl-long.47/) [![arXiv](https://img.shields.io/badge/arXiv-2311.09638-b31b1b.svg)](https://arxiv.org/abs/2311.09638) | Context use desiderata. |
| **Doc Representations** | <small>Learning Contextualized Document Representations for Healthcare Answer Retrieval</small> | [![ACM](https://img.shields.io/badge/ACM-Link-blue)](https://dl.acm.org/doi/10.1145/3366423.3380208) [![arXiv](https://img.shields.io/badge/arXiv-2002.00835-b31b1b.svg)](https://arxiv.org/abs/2002.00835) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/sebastianarnold/CDV) | Contextualized representations. |
| **Proprietary Data** | <small>EquinorQA: Large Language Models for Question Answering over Proprietary Data</small> | [![ECAI](https://img.shields.io/badge/ECAI-2024-blue)](https://xai.w.uib.no/files/2024/08/ECAI_2024-EquinorQA.pdf) | RAG on proprietary data. |
| **Japanese RAG** | <small>Exploring the Role of Knowledge Graph-Based RAG in Japanese Medical Question Answering with Small-Scale LLMs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2504.10982-b31b1b.svg)](https://arxiv.org/abs/2504.10982) | KG-RAG for Japanese Medical. |
| **Context Gen** | <small>Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.15268-b31b1b.svg)](https://arxiv.org/abs/2403.15268) [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=S0McroVcou) | Richer context imagination. |

---

## :brain: Specialized Domains (Mental Health, Finance, Legal)

> [!CAUTION]
> **High-Stakes & Regulatory Compliance**
>
> This section covers applications in sensitive domains where error tolerance is low and privacy is paramount. Papers here explore **Explainability** in financial forecasting, **Anonymity** in legal court decisions, and **Empathy** in mental health support. The focus is on domain-specific adaptation and ethical guardrails.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **Mental Health QA** | <small>MentalQA: An Annotated Arabic Corpus for Questions and Answers of Mental Healthcare</small> | [![arXiv](https://img.shields.io/badge/arXiv-2405.12619-b31b1b.svg)](https://arxiv.org/abs/2405.12619) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/hasanhuz/MentalQA) [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10600466/) | Arabic Mental Healthcare QA. |
| **Mental Health** | <small>Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for Chinese Mental Health</small> | [![arXiv](https://img.shields.io/badge/arXiv-2402.09151-b31b1b.svg)](https://arxiv.org/abs/2402.09151) [![ACL](https://img.shields.io/badge/ACL-ACL%20Findings-red)](https://aclanthology.org/2024.findings-acl.629/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/zwzzzQAQ/Chinese-MentalBERT) | Chinese MentalBERT. |
| **Mental Privacy** | <small>Privacy Aware Question-Answering System for Online Mental Health Risk Assessment</small> | [![ACL](https://img.shields.io/badge/ACL-BioNLP-red)](https://aclanthology.org/2023.bionlp-1.18/) | Privacy-aware QA. |
| **Financial QA** | <small>FinReflectKG - MultiHop: Financial QA Benchmark for Reasoning with KG Evidence</small> | [![OpenReview](https://img.shields.io/badge/OpenReview-PDF-blue)](https://openreview.net/pdf/303ebed0963c30d5f9659eb126a4b5da9ae55c66.pdf) | Financial multi-hop reasoning. |
| **Finance KG** | <small>FinQA: A Training-Free Dynamic Knowledge Graph QA System in Finance</small> | [![Springer](https://img.shields.io/badge/Springer-Link-blue)](https://link.springer.com/chapter/10.1007/978-3-031-70371-3_32) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/TtVoid/FinQA) | FinQA (Training-Free). |
| **Legal LLM** | <small>InLegalLLaMA: Indian Legal Knowledge Enhanced Large Language Model</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.738/) | Indian Legal Knowledge LLM. |
| **Legal RAG** | <small>Interpretable Long-Form Legal QA with Retrieval-Augmented LLMs</small> | [![AAAI](https://img.shields.io/badge/AAAI-30232-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/30232) [![arXiv](https://img.shields.io/badge/arXiv-2309.17050-b31b1b.svg)](https://arxiv.org/abs/2309.17050) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/maastrichtlawtech/lleqa) | Interpretability in Legal QA. |
| **Legal GraphRAG** | <small>Myanmar Law Cases and Proceedings Retrieval with GraphRAG</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10825155) | GraphRAG for Law. |
| **Legislative RAG** | <small>LexDrafter: Terminology Drafting for Legislative Documents using RAG</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.913/) [![arXiv](https://img.shields.io/badge/arXiv-2403.16295-b31b1b.svg)](https://arxiv.org/abs/2403.16295) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/achouhan93/LexDrafter) | Legislative drafting. |
| **Legal Retriever** | <small>UniLR: Unleashing the Power of LLMs on Multiple Legal Tasks with a Unified Legal Retriever</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202025-red)](https://aclanthology.org/2025.acl-long.584/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/LawLLM/UniLR) | Unified Legal Retriever. |
| **Re-Identification** | <small>Anonymity at Risk? Assessing Re-Identification Capabilities of LLMs in Court Decisions</small> | [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2024.findings-naacl.157/) [![arXiv](https://img.shields.io/badge/arXiv-2308.11103-b31b1b.svg)](https://arxiv.org/abs/2308.11103) | Re-ID in court decisions. |
| **Crypto QA** | <small>CryptOpiQA: A new Opinion and Question Answering dataset on Cryptocurrency</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.736/) [![Dataset](https://img.shields.io/badge/Zenodo-Dataset-blue)](https://zenodo.org/records/14469000) | Crypto sentiment/QA. |
| **Geopolitical** | <small>Scaling LLM-Based Knowledge Graph Generation: A Case Study of Italian Geopolitical News</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10825345) | Italian Geopolitical KG. |
| **e-Governance** | <small>An Open-Domain QA System for e-Governance</small> | [![arXiv](https://img.shields.io/badge/arXiv-2206.08046-b31b1b.svg)](https://arxiv.org/abs/2206.08046) [![ACL](https://img.shields.io/badge/ACL-CLIB-red)](https://aclanthology.org/2022.clib-1.12/) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/papers/2206.08046) | Open-domain QA. |
| **Education** | <small>Enhancing Textbook Question Answering with KG-Augmented LLMs</small> | [![PMLR](https://img.shields.io/badge/PMLR-Link-blue)](https://proceedings.mlr.press/v260/he25a.html) | KG-augmented Textbook QA. |
| **Education** | <small>Introducing CQuAE: A New French Contextualised QA Corpus for Education</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.808/) | CQuAE educational corpus. |
| **Grading** | <small>SteLLA: A Structured Grading System Using LLMs with RAG</small> | [![arXiv](https://img.shields.io/badge/arXiv-2501.09092-b31b1b.svg)](https://arxiv.org/abs/2501.09092) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/hefeiqiu/SteLLA) | SteLLA grading system. |
| **Linguistics** | <small>ELQA: A Corpus of Metalinguistic Questions and Answers about English</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202023-red)](https://aclanthology.org/2023.acl-long.113/) [![arXiv](https://img.shields.io/badge/arXiv-2205.00395-b31b1b.svg)](https://arxiv.org/abs/2205.00395) | Metalinguistic QA corpus. |
| **Consumer Health** | <small>Consumer Health Question Answering Using Off-the-Shelf Components</small> | [![Springer](https://img.shields.io/badge/Springer-Link-blue)](https://link.springer.com/chapter/10.1007/978-3-031-28238-6_48) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/apugachev/consumer-health-qa) | Off-the-shelf components. |
| **Health Prompting** | <small>Enhancing Consumer Health Question Reformulation: Chain-of-Thought Prompting Integrating Focus, Type, and User Knowledge Level</small> | [![ACL](https://img.shields.io/badge/ACL-CL4Health-red)](https://aclanthology.org/2024.cl4health-1.27/) [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/387025923_Enhancing_Consumer_Health_Question_Reformulation_Chain-of-Thought_Prompting_Integrating_Focus_Type_and_User_Knowledge_Level) | CoT for question reformulation. |

---

## :trophy: Benchmarks & Datasets

> [!NOTE]
> **Evaluating the State-of-the-Art**
>
> This section is a comprehensive repository of the gold-standard datasets required to train and evaluate medical QA systems. It spans **Multi-Choice Licensing Exams** (USMLE, Chinese Medical Exam), **Open-Ended Clinical QA**, and specialized **Shared Tasks** (e.g., BioASQ). These resources are essential for benchmarking performance across different modalities, languages, and reasoning complexities.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **Medical Dataset** | <small>Huatuo-26M: A Large-Scale Chinese Medical Question Answering Dataset</small> | [![arXiv](https://img.shields.io/badge/arXiv-2305.01526-b31b1b.svg)](https://arxiv.org/abs/2305.01526) [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2025.findings-naacl.211/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/FreedomIntelligence/Huatuo-26M) | 26M QA pairs dataset. |
| **Multi-Subject QA** | <small>MedMCQA: A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain QA</small> | [![PMLR](https://img.shields.io/badge/PMLR-CHIL-blue)](https://proceedings.mlr.press/v174/pal22a.html) [![arXiv](https://img.shields.io/badge/arXiv-2203.14371-b31b1b.svg)](https://arxiv.org/abs/2203.14371) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/medmcqa/medmcqa) | 194k Indian medical questions. |
| **Open Domain QA** | <small>MedQA: What Disease does this Patient Have? (USMLE-based)</small> | [![MDPI](https://img.shields.io/badge/MDPI-Applied%20Sciences-blue)](https://www.mdpi.com/2076-3417/11/14/6421) [![arXiv](https://img.shields.io/badge/arXiv-2009.13081-b31b1b.svg)](https://arxiv.org/abs/2009.13081) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/jind11/MedQA) | MedQA (USMLE-based). |
| **Clinical Benchmark** | <small>M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall</small> | [![arXiv](https://img.shields.io/badge/arXiv-2406.03699-b31b1b.svg)](https://arxiv.org/abs/2406.03699) [![ACL](https://img.shields.io/badge/ACL-ACL%20Findings-red)](https://aclanthology.org/2024.findings-acl.238/) | Clinical Reading Comp & Recall. |
| **French Benchmark** | <small>DrBenchmark: A Large Language Understanding Evaluation Benchmark for French Biomedical Domain</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.478/) | 20 tasks for French biomedical. |
| **Multilingual Med** | <small>Towards Building Multilingual Language Model for Medicine (MMedBench)</small> | [![arXiv](https://img.shields.io/badge/arXiv-2402.13963-b31b1b.svg)](https://arxiv.org/abs/2402.13963) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/henrychur/MultilingualMedQA) | MMedBench dataset. |
| **Strategy QA** | <small>StrategyQA: Did Aristotle Use a Laptop? A QA Benchmark with Implicit Reasoning Strategies</small> | [![arXiv](https://img.shields.io/badge/arXiv-2101.02235-b31b1b.svg)](https://arxiv.org/abs/2101.02235) [![Code](https://img.shields.io/badge/Code-AllenAI-blue)](https://allenai.org/data/strategyqa) | Implicit reasoning benchmark. |
| **Biomed Dataset** | <small>PubMedQA: A Dataset for Biomedical Research Question Answering</small> | [![arXiv](https://img.shields.io/badge/arXiv-1909.06146-b31b1b.svg)](https://arxiv.org/abs/1909.06146) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/pubmedqa/pubmedqa) [![Dataset](https://img.shields.io/badge/Dataset-Website-blue)](https://pubmedqa.github.io/) | PubMedQA dataset. |
| **Multilingual FAQ** | <small>MFAQ: a Multilingual FAQ Dataset</small> | [![ACL](https://img.shields.io/badge/ACL-MRQA-red)](https://aclanthology.org/2021.mrqa-1.1/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/clips/mfaq) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/datasets/clips/mfaq) | 6M FAQ pairs. |
| **Literary Fiction** | <small>LFED: A Literary Fiction Evaluation Dataset for Large Language Models</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2024.lrec-main.915/) [![arXiv](https://img.shields.io/badge/arXiv-2405.10166-b31b1b.svg)](https://arxiv.org/abs/2405.10166) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/tjunlp-lab/LFED) | Literary fiction eval. |
| **Dynamic QA** | <small>Let LLMs Take on the Latest Challenges! A Chinese Dynamic QA Benchmark</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.695/) [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=i35MCC7VHt) | Dynamic QA benchmark. |
| **Arabic Dataset** | <small>ArabicaQA: A Comprehensive Dataset for Arabic Question Answering</small> | [![arXiv](https://img.shields.io/badge/arXiv-2403.17848-b31b1b.svg)](https://arxiv.org/abs/2403.17848) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/DataScienceUIBK/ArabicaQA) | Comprehensive Arabic QA. |
| **Chinese Benchmark** | <small>CMB: A Comprehensive Medical Benchmark in Chinese</small> | [![ACL](https://img.shields.io/badge/ACL-NAACL-red)](https://aclanthology.org/2024.naacl-long.343/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/FreedomIntelligence/CMB) | Chinese medical benchmark. |
| **French Medical** | <small>FrenchMedMCQA: A French Multiple-Choice QA Dataset for Medical Domain</small> | [![ACL](https://img.shields.io/badge/ACL-LOUHI-red)](https://aclanthology.org/2022.louhi-1.5/) [![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace-orange)](https://huggingface.co/datasets/qanastek/FrenchMedMCQA) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/qanastek/FrenchMedMCQA) | French Multi-Choice Medical QA. |
| **Realistic QA** | <small>RealMedQA: A Pilot Biomedical QA Dataset Containing Realistic Clinical Questions</small> | [![PMC](https://img.shields.io/badge/PMC-Link-blue)](https://pmc.ncbi.nlm.nih.gov/articles/PMC12099375/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/gck25/RealMedQA) | Real clinical questions (NICE). |
| **Pharmacist Exam** | <small>ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination</small> | [![ACL](https://img.shields.io/badge/ACL-EMNLP-red)](https://aclanthology.org/2023.findings-emnlp.129/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/HITsz-TMG/ExplainCPE) | Pharmacist exam explanations. |
| **Arabic Health** | <small>AraHealthQA 2025: The First Shared Task on Arabic Health QA</small> | [![ACL](https://img.shields.io/badge/ACL-ArabicNLP-red)](https://aclanthology.org/2025.arabicnlp-sharedtasks.18/) [![arXiv](https://img.shields.io/badge/arXiv-2508.20047-b31b1b.svg)](https://arxiv.org/abs/2508.20047) | Shared task (Mental/General). |
| **Japanese Eval** | <small>JMedBench: A Benchmark for Evaluating Japanese Biomedical LLMs</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.395/) | JMedBench. |
| **EHR QA** | <small>DrugEHRQA: A QA Dataset on Structured and Unstructured EHR</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2022.lrec-1.117/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/jayetri/DrugEHRQA-A-Question-Answering-Dataset-on-Structured-and-Unstructured-Electronic-Health-Records) | DrugEHRQA. |
| **Radiology QA** | <small>RadQA: A QA Dataset to Improve Comprehension of Radiology Reports</small> | [![ACL](https://img.shields.io/badge/ACL-LREC-red)](https://aclanthology.org/2022.lrec-1.672/) | RadQA. |
| **Clinical QA** | <small>RJUA-QA: A Comprehensive QA Dataset for Clinical Reasoning in Urology</small> | [![arXiv](https://img.shields.io/badge/arXiv-2312.09785-b31b1b.svg)](https://arxiv.org/abs/2312.09785) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/alipay/RJU_Ant_QA) | Urology clinical reasoning. |
| **Short-Answer** | <small>ACTA: Short-Answer Grading in High-Stakes Medical Exams</small> | [![ACL](https://img.shields.io/badge/ACL-BEA-red)](https://aclanthology.org/2023.bea-1.36/) | Grading medical exams. |
| **Arabic Wikipedia** | <small>ArTrivia: Harvesting Arabic Wikipedia to Build A New Arabic QA Dataset</small> | [![ACL](https://img.shields.io/badge/ACL-ArabicNLP-red)](https://aclanthology.org/2023.arabicnlp-1.17/) | Arabic Wikipedia QA dataset. |
| **Scientific QA** | <small>SciQA: Extensive Analysis of the SciQA Benchmark with LLMs</small> | [![Conference](https://img.shields.io/badge/Conf-ESWC-blue)](https://2024.eswc-conferences.org/wp-content/uploads/2024/04/146640194.pdf) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/NIMI-research/SciQA-LLM) | SciQA benchmark analysis. |

---

## :camera: Multimodal & Visual QA

> [!IMPORTANT]
> **Beyond Text: The Convergence of Vision and Language**
>
> This section explores the frontier of **Multimodal AI**, where Large Language Models (LLMs) connect with visual data to "see" and interpret medical contexts. It covers **Medical Visual Question Answering (Med-VQA)**, **Radiology Report Generation**, and **Multimodal Knowledge Graphs**. These resources are pivotal for systems that must reason over heterogeneous data sources, such as aligning clinical notes with pixel-level evidence from X-rays, CT scans, and pathology slides.

| Topic | Full Title | Resources | Notes |
| :--- | :--- | :--- | :--- |
| **Multimodal QA** | <small>CLIPSyntel: CLIP and LLM Synergy for Multimodal Question Summarization in Healthcare</small> | [![arXiv](https://img.shields.io/badge/arXiv-2312.11541-b31b1b.svg)](https://arxiv.org/abs/2312.11541) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/AkashGhosh/CLIPSyntel-AAAI2024) | CLIP + LLM for summarization. |
| **Multimodal KG** | <small>VisualSem: A High-Quality Knowledge Graph for Vision and Language</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202021-red)](https://aclanthology.org/2021.acl-long.499/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/hweih/VisualSem) | VisualSem KG. |
| **Visual QA** | <small>Seeing Beyond: Enhancing Visual Question Answering with Multi-Modal Retrieval</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-industry.35/) | Multi-modal retrieval for VQA. |
| **EHR + CXR** | <small>EHRXQA: A Multi-Modal QA Dataset for Electronic Health Records with Chest X-ray Images</small> | [![NeurIPS](https://img.shields.io/badge/NeurIPS-OpenReview-blue)](https://openreview.net/forum?id=Pk2x7FPuZ4) [![arXiv](https://img.shields.io/badge/arXiv-2310.18652-b31b1b.svg)](https://arxiv.org/abs/2310.18652) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/baeseongsu/ehrxqa) | Multi-modal EHR QA. |
| **VQA Integration** | <small>Modality-Aware Integration with LLMs for Knowledge-Based Visual Question Answering</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%202024-red)](https://aclanthology.org/2024.acl-long.132/) [![arXiv](https://img.shields.io/badge/arXiv-2402.12728-b31b1b.svg)](https://arxiv.org/abs/2402.12728) | MAIL framework for VQA. |
| **Multimodal Sentiment** | <small>ConKI: Contrastive Knowledge Injection for Multimodal Sentiment Analysis</small> | [![ACL](https://img.shields.io/badge/ACL-ACL%20Findings-red)](https://aclanthology.org/2023.findings-acl.860/) [![arXiv](https://img.shields.io/badge/arXiv-2306.15796-b31b1b.svg)](https://arxiv.org/abs/2306.15796) | Contrastive knowledge injection. |
| **Visual Reasoning** | <small>Med-R1: Reinforcement Learning for Generalizable Medical Reasoning in VLMs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2503.13939-b31b1b.svg)](https://arxiv.org/abs/2503.13939) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/Yuxiang-Lai117/Med-R1) | RL for VLMs in medicine. |
| **Vietnamese VQA** | <small>Enhancing Vietnamese VQA through Curriculum Learning on Raw and Augmented Text</small> | [![arXiv](https://img.shields.io/badge/arXiv-2503.03285-b31b1b.svg)](https://arxiv.org/abs/2503.03285) | Vietnamese VQA. |
| **Drug Interaction** | <small>MKG-FENN: A Multimodal KG Fused End-to-End Neural Network for DDI Prediction</small> | [![AAAI](https://img.shields.io/badge/AAAI-28887-blue)](https://ojs.aaai.org/index.php/AAAI/article/view/28887) | Drug-drug interaction. |
| **Negative Sampling** | <small>Modality-Aware Negative Sampling for Multi-modal Knowledge Graph Embedding</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/10191314) | MANS negative sampling. |
| **Aspect-aware KG** | <small>AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities</small> | [![ACM](https://img.shields.io/badge/ACM-Link-blue)](https://dl.acm.org/doi/10.1145/3583780.3615023) [![arXiv](https://img.shields.io/badge/arXiv-2308.04992-b31b1b.svg)](https://arxiv.org/abs/2308.04992) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/theZJD/AspectMMKG) | AspectMMKG. |
| **Fact Verification** | <small>Multi-source Knowledge Enhanced Graph Attention Networks for Multimodal Fact Verification</small> | [![ResearchGate](https://img.shields.io/badge/ResearchGate-Link-green)](https://www.researchgate.net/publication/382271719_Multi-source_Knowledge_Enhanced_Graph_Attention_Networks_for_Multimodal_Fact_Verification) | Multi-source graph attention. |
| **Entity Tagging** | <small>Multimodal Entity Tagging with Multimodal Knowledge Base</small> | [![OpenReview](https://img.shields.io/badge/OpenReview-Link-blue)](https://openreview.net/forum?id=878288e498) | Multimodal Entity Tagging (MET). |
| **Noise-powered** | <small>Noise-powered Multi-modal Knowledge Graph Representation Framework</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.11/) | SNAG method. |
| **Spatial Expl** | <small>Spatially Grounded Explanations in Vision-Language Models for Document VQA</small> | [![arXiv](https://img.shields.io/badge/arXiv-2507.12490-b31b1b.svg)](https://arxiv.org/abs/2507.12490) | Spatially grounded explanations. |
| **Structure Guided** | <small>SGMEA: Structure-Guided Multimodal Entity Alignment</small> | [![ACL](https://img.shields.io/badge/ACL-COLING-red)](https://aclanthology.org/2025.coling-main.525/) | SGMEA. |
| **Spoken MRC** | <small>VlogQA: Task, Dataset, and Baseline Models for Vietnamese Spoken-Based MRC</small> | [![ACL](https://img.shields.io/badge/ACL-EACL-red)](https://aclanthology.org/2024.eacl-long.79/) [![Code](https://img.shields.io/badge/Code-GitHub-black)](https://github.com/sonlam1102/vlogqa) | VlogQA. |
| **Multimodal Doc** | <small>T2KG: Transforming Multimodal Document to Knowledge Graph</small> | [![ACL](https://img.shields.io/badge/ACL-RANLP-red)](https://aclanthology.org/2023.ranlp-1.43/) | T2KG. |
| **Visual Rel** | <small>Visual Relationship Detection With Visual-Linguistic Knowledge</small> | [![IEEE](https://img.shields.io/badge/IEEE-Xplore-blue)](https://ieeexplore.ieee.org/document/9366367) | Visual relationship detection. |
| **Zero-Shot Rel** | <small>Zero-Shot Relational Learning for Multimodal Knowledge Graphs</small> | [![arXiv](https://img.shields.io/badge/arXiv-2404.06220-b31b1b.svg)](https://arxiv.org/abs/2404.06220) | Zero-shot relational learning. |
| **Multimodal Repr** | <small>Enhancing Multimodal Knowledge Graph Representation Learning through Triple Contrastive Learning</small> | [![IJCAI](https://img.shields.io/badge/IJCAI-2024-blue)](https://www.ijcai.org/proceedings/2024/659) | Triple contrastive learning. |

---

## :telescope: Future Horizons

This repository chronicles a pivotal shift in Medical AI from static **Information Retrieval** to dynamic **Clinical Reasoning**. As the field matures, three defining paradigms are emerging:

* **The Agentic Shift:** Moving beyond passive chatbots to proactive **Copilots**. Systems like *MedAgents* and *Dr. Copilot* demonstrate that the future lies in LLMs that can plan, self-correct, and execute multi-step diagnostic workflows.
* **Multimodal Synergy:** True clinical understanding requires seeing as well as reading. The next generation of models achieves **Multimodal Fluency**, seamlessly synthesizing pixel-level evidence (X-rays, Pathology) with textual knowledge (Guidelines, EHRs).
* **Democratization & Safety:** As capabilities scale, so must responsibility. The focus is pivoting toward **Privacy-Preserving RAG** and **Linguistic Equity**, ensuring that life-saving AI is robust, compliant, and accessible across all languages from English to Amharic.

---

<div align="center">

This repository is licensed under the **[Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/)**, granting you the freedom to share and adapt this work for any purpose even commercially as long as you provide appropriate credit to the original research paper authors.

[![CC BY 4.0](https://i.creativecommons.org/l/by/4.0/88x31.png)](http://creativecommons.org/licenses/by/4.0/)

</div>
